<div align="center">

# üõ°Ô∏è DeepGuard

### Real-Time Deepfake Detection for Images, Videos & Live Screen Content

[![Python 3.10+](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.15-orange.svg)](https://tensorflow.org/)
[![License](https://img.shields.io/badge/License-Apache%202.0-green.svg)](LICENSE)
[![Gemini API](https://img.shields.io/badge/Gemini-API%20Ready-4285F4.svg)](https://ai.google.dev/)

**üèÜ Built for the [Gemini 3 Hackathon](https://gemini3.devpost.com/) by Google DeepMind**

[Features](#-key-features) ‚Ä¢ [Architecture](#Ô∏è-architecture) ‚Ä¢ [Quick Start](#Ô∏è-quick-start) ‚Ä¢ [Usage](#-usage) ‚Ä¢ [Gemini API](#-gemini-integration)

</div>

---

## üìñ Overview

DeepGuard is a **real-time deepfake detection system** capable of analyzing **images, videos, webcam feeds, and live on-screen content** (including social media and websites).

It is designed as a **lightweight, platform-agnostic AI safety engine** focused on real-world usability rather than benchmark-only performance.

---

## üöÄ Key Features

| Feature | Description |
|---------|-------------|
| üñºÔ∏è **Image Detection** | Analyze static images for deepfake manipulation |
| üéûÔ∏è **Video Detection** | Process video files with temporal aggregation |
| üì∑ **Live Webcam** | Real-time detection from webcam feed |
| üñ•Ô∏è **Screen Capture** | Monitor any on-screen content (social media, websites) |
| üß† **MesoNet CNN** | Lightweight face-based deepfake classification |
| üîç **Explainability** | Gemini-powered human-readable explanations |
| üß© **Modular Design** | Each pipeline works independently |

---

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                              DeepGuard System                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                      ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ                            ‚îÇ                            ‚îÇ
         ‚ñº                            ‚ñº                            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  INPUT SOURCES  ‚îÇ        ‚îÇ  INPUT SOURCES  ‚îÇ        ‚îÇ  INPUT SOURCES  ‚îÇ
‚îÇ                 ‚îÇ        ‚îÇ                 ‚îÇ        ‚îÇ                 ‚îÇ
‚îÇ  üì∑ Webcam      ‚îÇ        ‚îÇ  üñºÔ∏è Image       ‚îÇ        ‚îÇ  üñ•Ô∏è Screen      ‚îÇ
‚îÇ  üéûÔ∏è Video       ‚îÇ        ‚îÇ                 ‚îÇ        ‚îÇ    Capture      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                          ‚îÇ                          ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                                    ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ      FACE DETECTION (MTCNN)   ‚îÇ
                    ‚îÇ                               ‚îÇ
                    ‚îÇ  ‚Ä¢ Multi-face detection       ‚îÇ
                    ‚îÇ  ‚Ä¢ Bounding box extraction    ‚îÇ
                    ‚îÇ  ‚Ä¢ Face cropping & alignment  ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                                    ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   DEEPFAKE CLASSIFIER         ‚îÇ
                    ‚îÇ        (MesoNet CNN)          ‚îÇ
                    ‚îÇ                               ‚îÇ
                    ‚îÇ  Input: 256√ó256 RGB face      ‚îÇ
                    ‚îÇ  Output: Probability [0-1]    ‚îÇ
                    ‚îÇ                               ‚îÇ
                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
                    ‚îÇ  ‚îÇ Conv2D ‚Üí BatchNorm ‚Üí    ‚îÇ  ‚îÇ
                    ‚îÇ  ‚îÇ MaxPool (√ó4 blocks)     ‚îÇ  ‚îÇ
                    ‚îÇ  ‚îÇ ‚Üí Flatten ‚Üí Dense ‚Üí     ‚îÇ  ‚îÇ
                    ‚îÇ  ‚îÇ Dropout ‚Üí Sigmoid       ‚îÇ  ‚îÇ
                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ                               ‚îÇ
                    ‚ñº                               ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ SINGLE FRAME      ‚îÇ           ‚îÇ TEMPORAL          ‚îÇ
        ‚îÇ (Image Pipeline)  ‚îÇ           ‚îÇ AGGREGATION       ‚îÇ
        ‚îÇ                   ‚îÇ           ‚îÇ (Video/Live)      ‚îÇ
        ‚îÇ Direct output     ‚îÇ           ‚îÇ                   ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ Avg across frames ‚îÇ
                  ‚îÇ                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ                               ‚îÇ
                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ
                                  ‚ñº
                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                  ‚îÇ     EXPLANATION LAYER         ‚îÇ
                  ‚îÇ        (Gemini API)           ‚îÇ
                  ‚îÇ                               ‚îÇ
                  ‚îÇ  ‚Ä¢ Human-readable reasoning   ‚îÇ
                  ‚îÇ  ‚Ä¢ Confidence interpretation  ‚îÇ
                  ‚îÇ  ‚Ä¢ Deterministic fallback     ‚îÇ
                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ
                                  ‚ñº
                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                  ‚îÇ          OUTPUT               ‚îÇ
                  ‚îÇ                               ‚îÇ
                  ‚îÇ  {                            ‚îÇ
                  ‚îÇ    "label": "deepfake|real",  ‚îÇ
                  ‚îÇ    "score": 0.0-1.0,          ‚îÇ
                  ‚îÇ    "confidence": "high|med|low"‚îÇ
                  ‚îÇ    "explanation": "..."       ‚îÇ
                  ‚îÇ  }                            ‚îÇ
                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìÅ Project Structure

```
deepguard/
‚îú‚îÄ‚îÄ core/                          # Detection pipelines & logic
‚îÇ   ‚îú‚îÄ‚îÄ detector.py                # Core DeepfakeDetector class
‚îÇ   ‚îú‚îÄ‚îÄ face_detector_mtcnn.py     # MTCNN face detection wrapper
‚îÇ   ‚îú‚îÄ‚îÄ gemini_explainer.py        # Gemini API explanation layer
‚îÇ   ‚îú‚îÄ‚îÄ image_pipeline.py          # Static image analysis
‚îÇ   ‚îú‚îÄ‚îÄ video_pipeline.py          # Video file processing
‚îÇ   ‚îú‚îÄ‚îÄ live_pipeline.py           # Webcam real-time detection
‚îÇ   ‚îú‚îÄ‚îÄ screen_pipeline.py         # Screen capture monitoring
‚îÇ   ‚îî‚îÄ‚îÄ test_*.py                  # Unit tests
‚îÇ
‚îú‚îÄ‚îÄ mesonet/                       # MesoNet model (WIFS 2018)
‚îÇ   ‚îú‚îÄ‚îÄ classifiers.py             # Meso4, MesoInception4 architectures
‚îÇ   ‚îú‚îÄ‚îÄ weights/                   # Pretrained model weights
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Meso4_DF.h5            # Deepfake detection weights
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Meso4_F2F.h5           # Face2Face detection weights
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ MesoInception_*.h5     # Inception variant weights
‚îÇ   ‚îî‚îÄ‚îÄ test_images/               # Sample test images
‚îÇ
‚îú‚îÄ‚îÄ sample video/                  # Demo video for testing
‚îú‚îÄ‚îÄ requirements.txt               # Python dependencies
‚îú‚îÄ‚îÄ LICENSE                        # Apache 2.0 License
‚îú‚îÄ‚îÄ CONTRIBUTING.md                # Contribution guidelines
‚îú‚îÄ‚îÄ SECURITY.md                    # Security policy
‚îî‚îÄ‚îÄ README.md                      # This file
```

---

## ‚ö°Ô∏è Quick Start

### Prerequisites

- Python 3.10+
- pip
- Webcam (for live detection)

### Installation

```bash
# Clone the repository
git clone https://github.com/omtripathi52/deepguard.git
cd deepguard

# Create virtual environment
python -m venv venv

# Activate (Windows)
venv\Scripts\activate

# Activate (Linux/Mac)
# source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

---

## üéØ Usage

### üñºÔ∏è Image Detection

```bash
python -m core.image_pipeline --path face_0.jpg
# or
python -m core.image_pipeline --image face_0.jpg
```

### üéûÔ∏è Video Detection

```bash
python -m core.video_pipeline --path "path/to/video.mp4"
# or
python -m core.video_pipeline --video "path/to/video.mp4"
```

### üì∑ Webcam (Real-Time)

```bash
python -m core.live_pipeline
```
> Press `q` to quit

### üñ•Ô∏è Screen Capture

```bash
python -m core.screen_pipeline
```
> Press `Ctrl+C` to stop

---

## üîê Gemini Integration

DeepGuard is designed with **Gemini API integration** for AI-based reasoning and explanation of detection results.

### How It Works

| Component | Description |
|-----------|-------------|
| **Prompt Design** | Structured prompts for detection reasoning |
| **Model Discovery** | Automatic Gemini model enumeration |
| **Fallback System** | Deterministic explanations when API unavailable |

### Configuration

```bash
# Set your Gemini API key (optional - fallback works without it)
export GEMINI_API_KEY="your_api_key_here"
```

### Explanation Output Example

```
The system flagged this video as a potential deepfake with 84% confidence.
This may be due to subtle facial inconsistencies, unnatural motion patterns,
or artifacts commonly introduced by synthetic media generation.
```

---

## üõ†Ô∏è Tech Stack

| Technology | Purpose |
|------------|---------|
| **TensorFlow/Keras** | Deep learning framework |
| **MTCNN** | Multi-task face detection |
| **MesoNet** | Deepfake classification (WIFS 2018) |
| **OpenCV** | Image/video processing |
| **mss** | Cross-platform screen capture |
| **Google Gemini** | AI-powered explanations |

---

## üß© Use Cases

- ‚úÖ Social media deepfake monitoring
- ‚úÖ Content moderation pipelines
- ‚úÖ Media forensics & verification
- ‚úÖ Browser or application integration
- ‚úÖ AI safety and trust research

---

## üé¨ Note on Movie & Cinematic Content

DeepGuard may occasionally flag **movie scenes or cinematic footage** as potential deepfakes due to:

- Heavy visual effects (VFX)
- CGI-based face enhancement
- Cinematic color grading
- Compression artifacts

> **This is expected behavior.** The system is intentionally conservative, prioritizing safety over permissiveness.

---

## ‚ö†Ô∏è Disclaimer

DeepGuard is a **research prototype**. Predictions may be affected by:

- Video quality
- Lighting conditions
- Compression
- Artistic or cinematic effects

**Use as a decision-support tool, not as an absolute authority.**

---

## üå± Future Work

- [ ] Integration with stronger temporal models
- [ ] Transformer-based deepfake classifiers
- [ ] Mobile and browser deployment
- [ ] Multi-modal reasoning using Gemini
- [ ] Real-time confidence calibration

---

## üìú License

This project is licensed under the **Apache License 2.0** - see the [LICENSE](LICENSE) file for details.

---

## üôè Acknowledgements

- **MesoNet** architecture by [Darius Afchar et al.](https://arxiv.org/abs/1809.00888) (WIFS 2018)
- **MTCNN** for face detection
- **Google Gemini** for explainability layer

---

## ‚ú® Why This Project Matters

DeepGuard focuses on **real-world deployability** rather than benchmark-only performance.

By enabling **live, on-device deepfake detection**, it addresses a growing need for scalable AI safety tools in modern digital platforms.

---

<div align="center">

**Built with ‚ù§Ô∏è for the Gemini 3 Hackathon**

[‚¨Ü Back to Top](#Ô∏è-deepguard)

</div>
